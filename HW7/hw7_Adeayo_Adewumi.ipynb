{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import math\n",
    "import BitVector\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "import importlib\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from skimage import io, transform\n",
    "\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rgb_to_hsi_pixel(r, g, b):\n",
    "    # Normalize R, G, B to the range [0, 1]\n",
    "    R = r / 255.0\n",
    "    G = g / 255.0\n",
    "    B = b / 255.0\n",
    "\n",
    "    # Calculate M, m, and c\n",
    "    M = max(R, G, B)\n",
    "    m = min(R, G, B)\n",
    "    c = M - m\n",
    "\n",
    "    # Calculate Intensity (I)\n",
    "    I = (R + G + B) / 3\n",
    "\n",
    "    # Calculate Saturation (S)\n",
    "    if I == 0:\n",
    "        S = 0.0\n",
    "    else:\n",
    "        S = 1 - (m / I)\n",
    "\n",
    "    # Calculate Hue (H)\n",
    "    if c == 0:\n",
    "        H = 0.0\n",
    "    elif M == R:\n",
    "        H = (60 * ((G - B) / c) + 360) % 360\n",
    "    elif M == G:\n",
    "        H = (60 * ((B - R) / c) + 120) % 360\n",
    "    elif M == B:\n",
    "        H = (60 * ((R - G) / c) + 240) % 360\n",
    "    # # Normalize H to the range [0, 1] before returning\n",
    "    H = H / 360.0\n",
    "\n",
    "    return H, S, I\n",
    "\n",
    "def rgb_image_to_hsi(image):\n",
    "    # Ensure the image is in RGB format (OpenCV loads images in BGR format by default)\n",
    "    if image.shape[-1] == 3:  # Check if it's a color image with 3 channels\n",
    "        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    else:\n",
    "        raise ValueError(\"The provided image does not have 3 channels (RGB).\")\n",
    "\n",
    "    # Prepare an empty array for HSI with 3 channels (H, S, I)\n",
    "    hsi_array = np.zeros_like(image_rgb, dtype=float)\n",
    "\n",
    "    # Iterate over each pixel to convert it to HSI\n",
    "    for i in range(image_rgb.shape[0]):\n",
    "        for j in range(image_rgb.shape[1]):\n",
    "            r, g, b = image_rgb[i, j] / 255.0  # Normalize R, G, B to [0, 1]\n",
    "            h, s, i_intensity = rgb_to_hsi_pixel(r, g, b)\n",
    "            # Store the scaled H, S, and I values\n",
    "            hsi_array[i, j] = [h * 255, s * 255, i_intensity * 255]\n",
    "\n",
    "    # Extract the Hue channel and scale it to [0, 255]\n",
    "    hue_channel = hsi_array[:, :, 0]\n",
    "\n",
    "    # Convert the Hue channel to an 8-bit grayscale image (0-255 range)\n",
    "    hue_image = Image.fromarray(hue_channel.astype('uint8'), 'L')\n",
    "    \n",
    "    return hue_image\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def calculate_lbp(images, R=1, P=8):\n",
    "    lbp_hists=[]\n",
    "    for image in images:\n",
    "\n",
    "        # Extract hue value\n",
    "        image=rgb_image_to_hsi(image)\n",
    "        \n",
    "        # Initialize LBP histogram\n",
    "        lbp_hist = {t: 0 for t in range(P + 2)}\n",
    "        \n",
    "        image = image.resize((64, 64), Image.LANCZOS)\n",
    "        image=np.array(image)\n",
    "        width=image.shape[1]\n",
    "        height=image.shape[0]\n",
    "        # Constants\n",
    "        # lbp = [[0 for _ in range(height)] for _ in range(width)]\n",
    "        rowmax, colmax = height - R, width - R\n",
    "\n",
    "        # Loop through image pixels\n",
    "        for i in range(R, rowmax):\n",
    "            for j in range(R, colmax):\n",
    "                # print(f\"npixel at ({i},{j}):\")\n",
    "                pattern = []\n",
    "\n",
    "                # Generate pattern for the current pixel using P points\n",
    "                for p in range(P):\n",
    "                    # Calculate offsets for circular neighborhood\n",
    "                    angle = 2 * math.pi * p / P\n",
    "                    del_k = R * math.cos(angle)\n",
    "                    del_l = R * math.sin(angle)\n",
    "\n",
    "                    # Handle very small values close to zero for better stability\n",
    "                    if abs(del_k) < 0.001: del_k = 0.0\n",
    "                    if abs(del_l) < 0.001: del_l = 0.0\n",
    "\n",
    "                    # Calculate neighboring pixel coordinates\n",
    "                    k = i + del_k\n",
    "                    l = j + del_l\n",
    "                    k_base, l_base = int(k), int(l)\n",
    "\n",
    "                    # Calculate interpolation values\n",
    "                    delta_k = k - k_base\n",
    "                    delta_l = l - l_base\n",
    "\n",
    "                    # Fetch image values and compute the interpolated value at (k, l)\n",
    "                    image_val_at_p = 0\n",
    "                    if delta_k < 0.001 and delta_l < 0.001:\n",
    "                        image_val_at_p = float(image[k_base][l_base])\n",
    "                    elif delta_k < 0.001:\n",
    "                        image_val_at_p = (1 - delta_l) * image[k_base][l_base] + delta_l * image[k_base][l_base + 1]\n",
    "                    elif delta_l < 0.001:\n",
    "                        image_val_at_p = (1 - delta_k) * image[k_base][l_base] + delta_k * image[k_base + 1][l_base]\n",
    "                    else:\n",
    "                        # Bilinear interpolation for fractional (k, l)\n",
    "                        image_val_at_p = (\n",
    "                            (1 - delta_k) * (1 - delta_l) * image[k_base][l_base] +\n",
    "                            delta_k * (1 - delta_l) * image[k_base + 1][l_base] +\n",
    "                            (1 - delta_k) * delta_l * image[k_base][l_base + 1] +\n",
    "                            delta_k * delta_l * image[k_base + 1][l_base + 1]\n",
    "                        )\n",
    "\n",
    "                    # Append binary pattern based on comparison with center pixel value\n",
    "                    pattern.append(1 if image_val_at_p >= image[i][j] else 0)\n",
    "\n",
    "                # print(f\"pattern: {pattern}\")\n",
    "\n",
    "                # Convert pattern to BitVector and compute the minimal bit rotation\n",
    "                bv = BitVector.BitVector(bitlist=pattern)\n",
    "                intvals_for_circular_shifts = [int(bv << 1) for _ in range(P)]\n",
    "                minbv = BitVector.BitVector(intVal=min(intvals_for_circular_shifts), size=P)\n",
    "\n",
    "                # print(f\"minbv: {minbv}\")\n",
    "\n",
    "                # Calculate runs of consecutive bits in the minimal rotation\n",
    "                bvruns = minbv.runs()\n",
    "                encoding = None\n",
    "\n",
    "                # Determine encoding based on the number and pattern of runs\n",
    "                if len(bvruns) > 2:\n",
    "                    lbp_hist[P + 1] += 1\n",
    "                    encoding = P + 1\n",
    "                elif len(bvruns) == 1 and bvruns[0][0] == '1':\n",
    "                    lbp_hist[P] += 1\n",
    "                    encoding = P\n",
    "                elif len(bvruns) == 1 and bvruns[0][0] == '0':\n",
    "                    lbp_hist[0] += 1\n",
    "                    encoding = 0\n",
    "                else:\n",
    "                    lbp_hist[len(bvruns[1])] += 1\n",
    "                    encoding = len(bvruns[1])\n",
    "\n",
    "    lbp_hists.append(lbp_hist)            # print(f\"encoding: {encoding}\")\n",
    "\n",
    "    return lbp_hists\n",
    "\n",
    "\n",
    "# Plot the histogram\n",
    "\n",
    "def plot_hist(lbp_hists,img_names):\n",
    "    for i,lbp_hist in enumerate(lbp_hists):\n",
    "        plt.figure(figsize=(8, 5))\n",
    "        plt.bar(list(lbp_hist.keys()), lbp_hist.values(), color='g')\n",
    "\n",
    "        # Labeling the axes and title\n",
    "        plt.xlabel('Index')\n",
    "        plt.ylabel('Frequency')\n",
    "        plt.title(f'Histogram of LBP Patterns for {img_names[i]}')\n",
    "        plt.savefig(f'lpb_histogram_{img_names[i]}')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG19(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            # encode 1-1\n",
    "            nn.Conv2d(3, 3, kernel_size=(1, 1), stride=(1, 1)),\n",
    "            nn.Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode='reflect'),\n",
    "            nn.ReLU(inplace=True),  # relu 1-1\n",
    "            # encode 2-1\n",
    "            nn.Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode='reflect'),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False), #1/2\n",
    "\n",
    "            nn.Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode='reflect'),\n",
    "            nn.ReLU(inplace=True),  # relu 2-1\n",
    "            # encoder 3-1\n",
    "            nn.Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode='reflect'),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False), #1/4\n",
    "            nn.Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode='reflect'),\n",
    "            nn.ReLU(inplace=True),  # relu 3-1\n",
    "            # encoder 4-1\n",
    "            nn.Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode='reflect'),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode='reflect'),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode='reflect'),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False), #1/8\n",
    "\n",
    "            nn.Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode='reflect'),\n",
    "            nn.ReLU(inplace=True),  # relu 4-1\n",
    "            # rest of vgg not used\n",
    "            nn.Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode='reflect'),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode='reflect'),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode='reflect'),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False), #1/16\n",
    "\n",
    "            nn.Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode='reflect'),\n",
    "            nn.ReLU(inplace=True),  # relu 5-1\n",
    "            # nn.Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode='reflect'),\n",
    "            # nn.ReLU(inplace=True),\n",
    "            # nn.Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode='reflect'),\n",
    "            # nn.ReLU(inplace=True),\n",
    "            # nn.Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode='reflect'),\n",
    "            # nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def load_weights(self, path_to_weights):\n",
    "        vgg_model = torch.load(path_to_weights)\n",
    "        # Don't care about the extra weights\n",
    "        self.model.load_state_dict(vgg_model, strict=False)\n",
    "        for parameter in self.model.parameters():\n",
    "            parameter.requires_grad = False\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Input is numpy array of shape (H, W, 3)\n",
    "        # Output is numpy array of shape (N_l, H_l, W_l)\n",
    "        x = torch.from_numpy(x).permute(2, 0, 1).unsqueeze(0).float()\n",
    "        out = self.model(x)\n",
    "        out = out.squeeze(0).numpy()\n",
    "        return out\n",
    "        \n",
    "\n",
    "def class_for_name(module_name, class_name):\n",
    "    # load the module, will raise ImportError if module cannot be loaded\n",
    "    m = importlib.import_module(module_name)\n",
    "    return getattr(m, class_name)\n",
    "\n",
    "class CustomResNet(nn.Module):\n",
    "    def __init__(self,\n",
    "                 encoder='resnet50',\n",
    "                 pretrained=True):\n",
    "\n",
    "        super(CustomResNet, self).__init__()\n",
    "        assert encoder in ['resnet18', 'resnet34', 'resnet50', 'resnet101', 'resnet152'], \"Incorrect encoder type\"\n",
    "        # if encoder in ['resnet18', 'resnet34']:\n",
    "        #     filters = [64, 128, 256, 512]\n",
    "        # else:\n",
    "        #     filters = [256, 512, 1024, 2048]\n",
    "        resnet = class_for_name(\"torchvision.models\", encoder)(pretrained=pretrained)\n",
    "\n",
    "        for parameter in resnet.parameters():\n",
    "            parameter.requires_grad = False\n",
    "\n",
    "        self.firstconv = resnet.conv1  # H/2\n",
    "        self.firstbn = resnet.bn1\n",
    "        self.firstrelu = resnet.relu\n",
    "        self.firstmaxpool = resnet.maxpool  # H/4\n",
    "\n",
    "        # encoder\n",
    "        self.layer1 = resnet.layer1  # H/4\n",
    "        self.layer2 = resnet.layer2  # H/8\n",
    "        self.layer3 = resnet.layer3  # H/16\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Coarse and Fine Feature extraction using ResNet\n",
    "        Coarse Feature Map has smaller spatial sizes.\n",
    "        Arg:\n",
    "            x: (np.array) [H,W,C]\n",
    "        Rerurn:\n",
    "            xc: (np.array) [C_coarse, H/16, W/16]\n",
    "            xf: (np.array) [C_fine, H/8, W/8]\n",
    "        \"\"\"\n",
    "        x = torch.from_numpy(x).permute(2, 0, 1).unsqueeze(0).float()\n",
    "\n",
    "        x = self.firstrelu(self.firstbn(self.firstconv(x))) #1/2\n",
    "        x = self.firstmaxpool(x) #1/4\n",
    "\n",
    "        x = self.layer1(x) #1/4\n",
    "        xf = self.layer2(x) #1/8\n",
    "        xc = self.layer3(xf) #1/16\n",
    "\n",
    "        # convert xc, xf to numpy\n",
    "        xc = xc.squeeze(0).numpy()\n",
    "        xf = xf.squeeze(0).numpy()\n",
    "        return xc, xf\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_images(dir, train=True):\n",
    "    images = []\n",
    "    labels = []\n",
    "\n",
    "    # Define the directory path based on the mode (training or testing).\n",
    "    data_dir = os.path.join(dir, \"training\" if train else \"testing\")\n",
    "    \n",
    "    # Iterate over sorted image files in the specified directory.\n",
    "    for img_name in sorted(os.listdir(data_dir)):\n",
    "        # Skip hidden files like .DS_Store (MacOS metadata files).\n",
    "        if img_name.startswith('.'):\n",
    "            continue\n",
    "\n",
    "        # Identify the label based on the filename.\n",
    "        label = next((classes.index(cls) for cls in classes if cls in img_name), -1)\n",
    "        \n",
    "        # Proceed only if a valid label was found.\n",
    "        if label != -1:\n",
    "            # Read the image using cv2.\n",
    "            img_path = os.path.join(data_dir, img_name)\n",
    "            img=cv2.imread(img_path)\n",
    "\n",
    "            # Only add images with three channels (color images).\n",
    "            if img is not None and img.shape[-1] == 3:\n",
    "                labels.append(label)\n",
    "                images.append(img)\n",
    "    # print(labels)\n",
    "    return labels, images\n",
    "\n",
    "\n",
    "def get_features(model, images, labels, mode='train', modelname='vgg', config=None):\n",
    "    features=[]\n",
    "    for image in images:\n",
    "        img=transform.resize(image,(256,256))\n",
    "        if modelname=='resnet' and config=='coarse':\n",
    "            feature,_=model(img)\n",
    "        elif modelname=='resnet' and config=='fine':\n",
    "            _, feature=model(img)\n",
    "        else:\n",
    "            feature=model(img)\n",
    "        features.append(feature)\n",
    "    np.savez(f'{modelname}_{mode}_{config}_feature.npz',labels=labels, features=features)\n",
    "\n",
    "\n",
    "\n",
    "# def get_features(model, images, labels, mode='train', modelname='vgg', config=None):\n",
    "#     features = []\n",
    "#     for image in images:\n",
    "#         # Resize image to 256x256\n",
    "#         img = transform.resize(image, (256, 256))\n",
    "        \n",
    "#         # Convert single-channel hue to pseudo-RGB by stacking across 3 channels\n",
    "#         img = np.stack([img] * 3, axis=-1)\n",
    "        \n",
    "#         if modelname == 'resnet' and config == 'coarse':\n",
    "#             feature, _ = model(img)\n",
    "#         elif modelname == 'resnet' and config == 'fine':\n",
    "#             _, feature = model(img)\n",
    "#         else:\n",
    "#             feature = model(img)\n",
    "        \n",
    "#         features.append(feature)\n",
    "    \n",
    "#     np.savez(f'{modelname}_{mode}_{config}_feature.npz', labels=labels, features=features)\n",
    "\n",
    "\n",
    "\n",
    "def normalise_parameters(features):\n",
    "    \"\"\"Normalizes features by subtracting the mean and dividing by the standard deviation.\n",
    "\n",
    "    Args:\n",
    "        features: A NumPy array of features with shape (num_samples, num_features, feature_dim).\n",
    "\n",
    "    Returns:\n",
    "        A NumPy array of normalized features with the same shape as the input.\n",
    "    \"\"\"\n",
    "\n",
    "    # Reshape features for efficient broadcasting\n",
    "    features = features.reshape(-1, features.shape[-1])\n",
    "\n",
    "    # Calculate mean and standard deviation along the last dimension\n",
    "    mean = features.mean(axis=0)\n",
    "    std = features.std(axis=0)\n",
    "\n",
    "    # Normalize features\n",
    "    normalized_features = (features - mean) / std\n",
    "\n",
    "    # Reshape normalized features back to the original shape\n",
    "    normalized_features = normalized_features.reshape(features.shape)\n",
    "\n",
    "    return normalized_features\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_gm(features):\n",
    "    gm_train = []\n",
    "    np.random.seed(0)  # Set seed once\n",
    "    for ft in features:\n",
    "        ft = ft.reshape(512, -1)\n",
    "        gm = ft @ ft.T\n",
    "        gm_flat = gm.flatten()\n",
    "        \n",
    "        # Check if enough elements for sampling\n",
    "        if len(gm_flat) < 1024:\n",
    "            raise ValueError(\"Gram matrix is too small for sampling 1024 elements.\")\n",
    "        \n",
    "        gm_sample = np.random.choice(gm_flat, 1024, replace=False)\n",
    "        gm_train.append(gm_sample)\n",
    "        \n",
    "    return gm_train\n",
    "\n",
    "\n",
    "\n",
    "def plot_gram_matrix(model, gm_train, training_labels, classes, P, R):\n",
    "    # Identify one sample index for each class\n",
    "    sample_indices = []\n",
    "    for class_name in classes:\n",
    "        for i, label in enumerate(training_labels):\n",
    "            if classes[label] == class_name:\n",
    "                sample_indices.append(i)\n",
    "                break  # Stop after finding the first match for each class\n",
    "    # Plot Gram matrices for each identified sample\n",
    "    for idx, class_name in zip(sample_indices, classes):\n",
    "        plt.figure()\n",
    "        gm_2D = gm_train[idx].reshape(32, 32)\n",
    "        plt.imshow(gm_2D, cmap='viridis')  # Plot Gram matrix of the specific image\n",
    "        plt.colorbar()\n",
    "        plt.title(f\"{class_name} - 2D Gram Matrix Heatmap ({model}_R={R}_P={P})\")\n",
    "        \n",
    "        # Save each plot with a unique filename\n",
    "        plt.savefig(f'{class_name}_2D_Gram_Matrix_Heatmap_{model}_R={R}_P={P}.png')\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(model, test_labels, pred_labels, R, P):\n",
    "    # Calculate the confusion matrix\n",
    "    cm = confusion_matrix(test_labels, pred_labels)\n",
    "\n",
    "    # Plot the confusion matrix\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\")\n",
    "    plt.xlabel(\"Predicted Label\")\n",
    "    plt.ylabel(\"True Label\")\n",
    "    plt.title(f\"Confusion Matrix ({model}) R={R}, P={P}\")\n",
    "    plt.savefig(f'confusion_matrix ({model}) R={R}, P={P}.png')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Define a function to save images of correctly and incorrectly classified samples\n",
    "def save_classification_images(model, test_images, test_labels, pred_labels, classes, P, R):\n",
    "    # Initialize dictionaries to track saved images for each class\n",
    "    saved_correct = {class_name: False for class_name in classes}\n",
    "    saved_incorrect = {class_name: False for class_name in classes}\n",
    "\n",
    "    for idx, (image, true_label, pred_label) in enumerate(zip(test_images, test_labels, pred_labels)):\n",
    "        true_class = classes[true_label]\n",
    "        pred_class = classes[pred_label]\n",
    "\n",
    "        # Check if it's correctly or incorrectly classified and save accordingly\n",
    "        if true_class == pred_class and not saved_correct[true_class]:  # Correctly classified\n",
    "            plt.figure()\n",
    "            plt.imshow(image)  # Assuming image is in RGB format\n",
    "            plt.title(f\"Correctly Classified: {true_class}\")\n",
    "            plt.xlabel(f\"Predicted: {pred_class} | Ground Truth: {true_class}\")\n",
    "            plt.savefig(f\"{model}_correct_{true_class}_P={P}_R={R}.png\")\n",
    "            plt.close()\n",
    "            saved_correct[true_class] = True  # Mark as saved\n",
    "\n",
    "        elif true_class != pred_class and not saved_incorrect[true_class]:  # Misclassified\n",
    "            plt.figure()\n",
    "            plt.imshow(image)  # Assuming image is in RGB format\n",
    "            plt.title(f\"Misclassified: {true_class} as {pred_class}\")\n",
    "            plt.xlabel(f\"Predicted: {pred_class} | Ground Truth: {true_class}\")\n",
    "            plt.savefig(f\"{model}_incorrect_{true_class}_P={P}_R={R}.png\")\n",
    "            plt.close()\n",
    "            saved_incorrect[true_class] = True  # Mark as saved\n",
    "\n",
    "        # Break the loop once we have both correct and incorrect for each class\n",
    "        if all(saved_correct.values()) and all(saved_incorrect.values()):\n",
    "            break\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "img_dir='HW7-Auxilliary/data'\n",
    "# *****************************************************************\n",
    "# *****************************************************************\n",
    "# *****************************************************************\n",
    "R, P = 1, 8\n",
    "model=VGG19()\n",
    "model.load_weights('HW7-Auxilliary/vgg_normalized.pth')  \n",
    "classes=['cloudy','rain','shine','sunrise']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "training_labels,training_images = get_images(img_dir)\n",
    "testing_labels, testing_images= get_images(img_dir, train=False)\n",
    "\n",
    "\n",
    "\n",
    "lbp_train_result=calculate_lbp(training_images, R, P)\n",
    "# np.savez('train_lbp_net.npz', labels=training_labels, features=lbp_train_result)\n",
    "lbp_test_result=calculate_lbp(testing_images, R, P)\n",
    "# np.savez('test_lbp_net.npz', labels=testing_labels, features=lbp_test_result)\n",
    "\n",
    "\n",
    "# Convert training images to hue channel images\n",
    "# training_images = [np.array(rgb_image_to_hsi(img)) for img in training_images_rgb]\n",
    "\n",
    "# # Convert testing images to hue channel images\n",
    "# testing_images = [np.array(rgb_image_to_hsi(img)) for img in testing_images_rgb]\n",
    "\n",
    "get_features(model, training_images, training_labels)\n",
    "get_features(model, testing_images, testing_labels, mode='test')\n",
    "\n",
    "train_data=np.load('vgg_train_None_feature.npz')\n",
    "test_data=np.load('vgg_test_None_feature.npz')\n",
    "train_features, train_labels = train_data['features'], train_data['labels']\n",
    "test_features, test_labels = test_data['features'], test_data['labels']\n",
    "\n",
    "print(len(train_features))\n",
    "gm_train = get_gm(train_features)\n",
    "gm_test = get_gm(test_features)\n",
    "\n",
    "\n",
    "\n",
    "svm_classifier = SVC(kernel='linear')  \n",
    "# Fit the model to the training data\n",
    "svm_classifier.fit(gm_train, train_labels)\n",
    "\n",
    "# # Make predictions on the test set\n",
    "pred_labels = svm_classifier.predict(gm_test)\n",
    "\n",
    "# # Calculate the accuracy score\n",
    "# train_score = svm_classifier.score(gm_train, train_labels)\n",
    "test_score = svm_classifier.score(gm_test, test_labels)\n",
    "\n",
    "## Plot lbp \n",
    "# lbp_result=calculate_lbp([cv2.imread('cloudy156.jpg'), cv2.imread('sunrise132.jpg'), cv2.imread('rain67.jpg'), cv2.imread('shine50.jpg')])\n",
    "# plot_hist(lbp_result, ['cloudy156.jpg', 'sunrise132.jpg','rain67.jpg', 'shine50.jpg'])\n",
    "\n",
    "\n",
    "print('VGG score',test_score)\n",
    "# plot_confusion_matrix('vgg', test_labels, pred_labels, R, P)\n",
    "# plot_gram_matrix('vgg', gm_train, train_labels, classes, P, R)\n",
    "# save_classification_images('vgg',training_images, test_labels, pred_labels, classes, P, R)\n",
    "\n",
    "# *****************************************************************\n",
    "# *****************************************************************\n",
    "# *****************************************************************\n",
    "# resnet_config='coarse'\n",
    "# encoder_name='resnet50' # Valid options ['resnet18', 'resnet34', 'resnet50', 'resnet101', 'resnet152']\n",
    "# # CustomResNet will download the model weights from pytorch to the following path:\n",
    "#     # resnet50 ~/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth  Size - 98MB\n",
    "\n",
    "# resnet = CustomResNet(encoder=encoder_name)\n",
    "# get_features(resnet, training_images, training_labels, modelname='resnet', config=resnet_config)\n",
    "# get_features(resnet, testing_images, testing_labels, mode='test', modelname='resnet', config=resnet_config)\n",
    "\n",
    "# resnet_train_data=np.load('resnet_train_coarse_feature.npz')\n",
    "# resnet_test_data=np.load('resnet_test_coarse_feature.npz')\n",
    "# train_features, train_labels = train_data['features'], train_data['labels']\n",
    "# test_features, test_labels = test_data['features'], test_data['labels']\n",
    "\n",
    "\n",
    "# gm_train = get_gm(train_features)\n",
    "# gm_test = get_gm(test_features)\n",
    "\n",
    "# svm_classifier_resnet = SVC(kernel='linear')  \n",
    "# # Fit the model to the training data\n",
    "# svm_classifier_resnet.fit(gm_train, train_labels)\n",
    "\n",
    "# # # Make predictions on the test set\n",
    "# resnet_pred_labels = svm_classifier_resnet.predict(gm_test)\n",
    "\n",
    "# # # Calculate the accuracy score\n",
    "# # train_score = svm_classifier.score(gm_train, train_labels)\n",
    "# resnet_test_score = svm_classifier_resnet.score(gm_test, test_labels)\n",
    "\n",
    "# ## Plot lbp \n",
    "# # lbp_result=calculate_lbp([cv2.imread('cloudy156.jpg'), cv2.imread('sunrise132.jpg'), cv2.imread('rain67.jpg'), cv2.imread('shine50.jpg')])\n",
    "# # plot_hist(lbp_result, ['cloudy156.jpg', 'sunrise132.jpg','rain67.jpg', 'shine50.jpg'])\n",
    "\n",
    "\n",
    "# print(f'{resnet_config} Resnet score',resnet_test_score)\n",
    "# # plot_confusion_matrix(f'{resnet_config}_resnet', test_labels, resnet_pred_labels, R, P)\n",
    "# # plot_gram_matrix(f'{resnet_config}_resnet', gm_train, train_labels, classes, P, R)\n",
    "# # save_classification_images(f'{resnet_config} Resnet score',testing_images, test_labels, pred_labels, classes, P, R)\n",
    "\n",
    "# # *****************************************************************\n",
    "# # *****************************************************************\n",
    "# # *****************************************************************\n",
    "# resnet_config='fine'\n",
    "# encoder_name='resnet50' # Valid options ['resnet18', 'resnet34', 'resnet50', 'resnet101', 'resnet152']\n",
    "# # CustomResNet will download the model weights from pytorch to the following path:\n",
    "#     # resnet50 ~/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth  Size - 98MB\n",
    "\n",
    "# resnet = CustomResNet(encoder=encoder_name)\n",
    "# get_features(resnet, training_images, training_labels, modelname='resnet', config=resnet_config)\n",
    "# get_features(resnet, testing_images, testing_labels, mode='test', modelname='resnet', config=resnet_config)\n",
    "\n",
    "# resnet_train_data=np.load('resnet_train_fine_feature.npz')\n",
    "# resnet_test_data=np.load('resnet_test_fine_feature.npz')\n",
    "# train_features, train_labels = train_data['features'], train_data['labels']\n",
    "# test_features, test_labels = test_data['features'], test_data['labels']\n",
    "\n",
    "\n",
    "# gm_train = get_gm(train_features)\n",
    "# gm_test = get_gm(test_features)\n",
    "\n",
    "# svm_classifier_resnet = SVC(kernel='linear')  \n",
    "# # Fit the model to the training data\n",
    "# svm_classifier_resnet.fit(gm_train, train_labels)\n",
    "\n",
    "# # # Make predictions on the test set\n",
    "# resnet_pred_labels = svm_classifier_resnet.predict(gm_test)\n",
    "\n",
    "# # # Calculate the accuracy score\n",
    "# # train_score = svm_classifier.score(gm_train, train_labels)\n",
    "# resnet_test_score = svm_classifier_resnet.score(gm_test, test_labels)\n",
    "\n",
    "# ## Plot lbp \n",
    "# # lbp_result=calculate_lbp([cv2.imread('cloudy156.jpg'), cv2.imread('sunrise132.jpg'), cv2.imread('rain67.jpg'), cv2.imread('shine50.jpg')])\n",
    "# # plot_hist(lbp_result, ['cloudy156.jpg', 'sunrise132.jpg','rain67.jpg', 'shine50.jpg'])\n",
    "\n",
    "\n",
    "# print(f'{resnet_config} Resnet score',resnet_test_score)\n",
    "# # plot_confusion_matrix(f'{resnet_config}_resnet', test_labels, resnet_pred_labels, R, P)\n",
    "# # plot_gram_matrix(f'{resnet_config}_resnet', gm_train, train_labels, classes, P, R)\n",
    "# # save_classification_images(f'{resnet_config} Resnet score',testing_images, test_labels, pred_labels, classes, P, R)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envece",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
