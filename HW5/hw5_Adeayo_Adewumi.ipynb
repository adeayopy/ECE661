{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some help was used from ChatGPT for code optimization and commenting\n",
    "import cv2\n",
    "import numpy as np\n",
    "import random\n",
    "from scipy.optimize import least_squares\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_homography(p1, p2):\n",
    "    # Calculate homography matrix using the Direct Linear Transform (DLT)\n",
    "    A = []\n",
    "    for i in range(len(p1)):\n",
    "        x1, y1 = p1[i][0], p1[i][1]\n",
    "        x2, y2 = p2[i][0], p2[i][1]\n",
    "        A.append([-x1, -y1, -1, 0, 0, 0, x1 * x2, y1 * x2, x2])\n",
    "        A.append([0, 0, 0, -x1, -y1, -1, x1 * y2, y1 * y2, y2])\n",
    "    A = np.array(A)\n",
    "    U, S, V = np.linalg.svd(A)\n",
    "    H = V[-1].reshape(3, 3)\n",
    "    return H / H[2, 2]  # Normalize the homography\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def apply_homography(H, pt):\n",
    "    # Apply homography to a point\n",
    "    pt = np.array([pt[0], pt[1], 1.0])\n",
    "    transformed_pt = np.dot(H, pt)\n",
    "    transformed_pt /= transformed_pt[2]  # Normalize\n",
    "    return transformed_pt[0], transformed_pt[1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ransac_outlier_rejection(pts1, pts2, threshold=5.0, max_iterations=1000):\n",
    "    best_H = None\n",
    "    max_inliers = 0\n",
    "    best_inliers = []\n",
    "    best_outliers = []\n",
    "\n",
    "    for _ in range(max_iterations):\n",
    "        # Step 1: Randomly select 4 points\n",
    "        indices = random.sample(range(len(pts1)), 4)\n",
    "        p1_sample = [pts1[i] for i in indices]\n",
    "        p2_sample = [pts2[i] for i in indices]\n",
    "\n",
    "        # Step 2: Compute homography based on the sample\n",
    "        H = compute_homography(p1_sample, p2_sample)\n",
    "\n",
    "        inliers = []\n",
    "        outliers = []\n",
    "\n",
    "        # Step 3: Compute reprojection error for all points\n",
    "        for i in range(len(pts1)):\n",
    "            projected_pt = apply_homography(H, pts1[i])\n",
    "            error = np.linalg.norm(np.array(projected_pt) - np.array(pts2[i]))\n",
    "\n",
    "            if error < threshold:\n",
    "                inliers.append(i)\n",
    "            else:\n",
    "                outliers.append(i)\n",
    "\n",
    "        # Step 4: Keep the model with the most inliers\n",
    "        if len(inliers) > max_inliers:\n",
    "            max_inliers = len(inliers)\n",
    "            best_H = H\n",
    "            best_inliers = inliers\n",
    "            best_outliers = outliers\n",
    "\n",
    "    return best_H, best_inliers, best_outliers\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_inliers_outliers(img1, img2, keypoints1, keypoints2, inliers, outliers, output_name):\n",
    "    # Create an image combining the two images side by side\n",
    "    h1, w1 = img1.shape[:2]\n",
    "    h2, w2 = img2.shape[:2]\n",
    "    combined_img = np.zeros((max(h1, h2), w1 + w2, 3), dtype=np.uint8)\n",
    "    combined_img[:h1, :w1] = img1\n",
    "    combined_img[:h2, w1:] = img2\n",
    "\n",
    "    # Plot inliers in blue and outliers in red\n",
    "    for i in inliers:\n",
    "        pt1 = np.int32(keypoints1[i])\n",
    "        pt2 = np.int32(keypoints2[i]) + np.array([w1, 0])  # Shift pt2 horizontally\n",
    "        cv2.line(combined_img, tuple(pt1), tuple(pt2), (0, 0, 255), 1)\n",
    "        cv2.circle(combined_img, tuple(pt1), 5, (255, 0, 0), -1)\n",
    "        cv2.circle(combined_img, tuple(pt2), 5, (255, 0, 0), -1)\n",
    "\n",
    "    for i in outliers:\n",
    "        pt1 = np.int32(keypoints1[i])\n",
    "        pt2 = np.int32(keypoints2[i]) + np.array([w1, 0])  # Shift pt2 horizontally\n",
    "        cv2.line(combined_img, tuple(pt1), tuple(pt2), (0, 0, 255), 1)\n",
    "        cv2.circle(combined_img, tuple(pt1), 5, (0, 0, 255), -1)\n",
    "        cv2.circle(combined_img, tuple(pt2), 5, (0, 0, 255), -1)\n",
    "\n",
    "    cv2.imwrite(output_name, combined_img)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_homography_from_inliers(pts1, pts2, inliers):\n",
    "    # Extract the inlier points from the original point sets\n",
    "    inlier_pts1 = [pts1[i] for i in inliers]\n",
    "    inlier_pts2 = [pts2[i] for i in inliers]\n",
    "\n",
    "    # Compute homography using the inlier points\n",
    "    H_inliers = compute_homography(inlier_pts1, inlier_pts2)\n",
    "\n",
    "    return H_inliers, inlier_pts1, inlier_pts2\n",
    "\n",
    "\n",
    "# def reprojection_error(h, pts1, pts2):\n",
    "#     \"\"\"Computes the reprojection error between projected points and actual points.\"\"\"\n",
    "#     H = h.reshape((3, 3))  # Reshape h into the 3x3 homography matrix\n",
    "#     total_error = []\n",
    "    \n",
    "#     for i in range(len(pts1)):\n",
    "#         pt1 = pts1[i]\n",
    "#         pt2 = pts2[i]\n",
    "#         pt1_proj = apply_homography(H, pt1)\n",
    "#         error = np.linalg.norm(pt2 - pt1_proj)  # Euclidean distance error\n",
    "#         total_error.append(error)\n",
    "    \n",
    "#     return np.array(total_error)\n",
    "\n",
    "\n",
    "def refine_homography(H_init, pts1, pts2):\n",
    "    \"\"\"Refine homography using nonlinear least squares optimization.\"\"\"\n",
    "    h_init = H_init.flatten()  # Flatten the 3x3 homography matrix to a 9-element vector\n",
    "\n",
    "    # Use Levenberg-Marquardt optimization to minimize reprojection error\n",
    "    result = least_squares(reprojection_error, h_init, args=(pts1, pts2))\n",
    "\n",
    "    # Reshape the optimized homography back into a 3x3 matrix\n",
    "    H_refined = result.x.reshape((3, 3))\n",
    "\n",
    "    # Normalize the homography matrix\n",
    "    H_refined /= H_refined[2, 2]\n",
    "\n",
    "    return H_refined\n",
    "\n",
    "# # Extracredit\n",
    "def reprojection_error(h, pts1, pts2):\n",
    "    \"\"\"Calculate the reprojection error between pts1 and pts2 given homography parameters.\"\"\"\n",
    "    # Reshape h back into a 3x3 matrix\n",
    "    H = h.reshape(3, 3)\n",
    "\n",
    "    # Apply homography to pts1\n",
    "    pts1_homo = np.hstack((pts1, np.ones((pts1.shape[0], 1))))\n",
    "    projected_pts = (H @ pts1_homo.T).T\n",
    "\n",
    "    # Normalize to convert from homogeneous to Cartesian coordinates\n",
    "    projected_pts /= projected_pts[:, 2][:, np.newaxis]\n",
    "\n",
    "    # Reprojection error (difference between projected points and actual points)\n",
    "    error = projected_pts[:, :2] - pts2\n",
    "\n",
    "    return error.flatten()\n",
    "\n",
    "# Extracredit\n",
    "def jacobian(h, pts1):\n",
    "    \"\"\"Calculate the Jacobian matrix of the reprojection error with respect to h.\"\"\"\n",
    "    H = h.reshape(3, 3)\n",
    "    num_points = pts1.shape[0]\n",
    "    J = np.zeros((2 * num_points, 9))\n",
    "\n",
    "    for i in range(num_points):\n",
    "        x, y = pts1[i, 0], pts1[i, 1]\n",
    "\n",
    "        # Project the point using the homography\n",
    "        denom = (H[2, 0] * x + H[2, 1] * y + H[2, 2])\n",
    "        x_prime = (H[0, 0] * x + H[0, 1] * y + H[0, 2]) / denom\n",
    "        y_prime = (H[1, 0] * x + H[1, 1] * y + H[1, 2]) / denom\n",
    "\n",
    "        # Derivatives of the projected point with respect to h\n",
    "        J[2 * i, 0] = x / denom\n",
    "        J[2 * i, 1] = y / denom\n",
    "        J[2 * i, 2] = 1 / denom\n",
    "        J[2 * i, 6] = -x_prime * x / denom\n",
    "        J[2 * i, 7] = -x_prime * y / denom\n",
    "        J[2 * i, 8] = -x_prime / denom\n",
    "\n",
    "        J[2 * i + 1, 3] = x / denom\n",
    "        J[2 * i + 1, 4] = y / denom\n",
    "        J[2 * i + 1, 5] = 1 / denom\n",
    "        J[2 * i + 1, 6] = -y_prime * x / denom\n",
    "        J[2 * i + 1, 7] = -y_prime * y / denom\n",
    "        J[2 * i + 1, 8] = -y_prime / denom\n",
    "\n",
    "    return J\n",
    "\n",
    "# Extracredit\n",
    "def refine_homography_lm(H_init, pts1, pts2, max_iters=100, lambda_init=1e-3, tol=1e-6):\n",
    "    \"\"\"Refine the homography using the Levenberg-Marquardt algorithm.\"\"\"\n",
    "    # Convert pts1 and pts2 to NumPy arrays if they are not already\n",
    "    pts1 = np.array(pts1)\n",
    "    pts2 = np.array(pts2)\n",
    "\n",
    "    h = H_init.flatten()  # Flatten the initial homography to a vector\n",
    "    lambda_param = lambda_init\n",
    "    prev_error = np.inf\n",
    "\n",
    "    for iteration in range(max_iters):\n",
    "        # Compute reprojection error\n",
    "        error = reprojection_error(h, pts1, pts2)\n",
    "        error_norm = np.linalg.norm(error)\n",
    "\n",
    "        if error_norm < tol:\n",
    "            print(f\"Converged after {iteration} iterations\")\n",
    "            break\n",
    "\n",
    "        # Compute the Jacobian\n",
    "        J = jacobian(h, pts1)\n",
    "\n",
    "        # Compute the update: (J^T J + lambda I) delta_h = J^T error\n",
    "        JTJ = J.T @ J\n",
    "        JTe = J.T @ error\n",
    "        delta_h = np.linalg.inv(JTJ + lambda_param * np.eye(9)) @ JTe\n",
    "\n",
    "        # Update h\n",
    "        h_new = h - delta_h\n",
    "\n",
    "        # Compute new reprojection error\n",
    "        new_error = reprojection_error(h_new, pts1, pts2)\n",
    "        new_error_norm = np.linalg.norm(new_error)\n",
    "\n",
    "        # Check if the new error is smaller\n",
    "        if new_error_norm < error_norm:\n",
    "            # Accept the new solution\n",
    "            h = h_new\n",
    "            prev_error = new_error_norm\n",
    "            lambda_param /= 10  # Reduce lambda (more Gauss-Newton)\n",
    "        else:\n",
    "            # Reject the new solution and increase lambda (more gradient descent)\n",
    "            lambda_param *= 10\n",
    "\n",
    "        # Check for convergence based on error difference\n",
    "        if abs(prev_error - new_error_norm) < tol:\n",
    "            print(f\"Converged after {iteration} iterations with error {new_error_norm}\")\n",
    "            break\n",
    "\n",
    "    # Reshape the refined homography back into 3x3 matrix\n",
    "    H_refined = h.reshape(3, 3)\n",
    "    H_refined /= H_refined[2, 2]  # Normalize the homography\n",
    "\n",
    "    return H_refined\n",
    "\n",
    "\n",
    "\n",
    "def compute_average_error(H, pts1, pts2):\n",
    "    \"\"\"Computes the average reprojection error using the given homography.\"\"\"\n",
    "    projected_pts = []\n",
    "    for pt in pts1:\n",
    "        projected_pt = apply_homography(H, pt)\n",
    "        projected_pts.append(projected_pt)\n",
    "\n",
    "    projected_pts = np.array(projected_pts)\n",
    "    error = np.linalg.norm(pts2 - projected_pts, axis=1)  # Euclidean distance for each point\n",
    "    avg_error = np.mean(error)  # Average reprojection error\n",
    "    \n",
    "    return avg_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def sift_feature_matching_ransac(img1, img2, ratio_test=0.75, ransac_thresh=5.0, output_name='pair1_2.jpg'):\n",
    "    # Step 1: Initialize the SIFT detector\n",
    "    sift = cv2.SIFT_create()\n",
    "\n",
    "    # Step 2: Detect keypoints and compute descriptors for both images\n",
    "    keypoints1, descriptors1 = sift.detectAndCompute(img1, None)\n",
    "    keypoints2, descriptors2 = sift.detectAndCompute(img2, None)\n",
    "\n",
    "    # Step 3: Use BFMatcher to match descriptors\n",
    "    bf = cv2.BFMatcher(cv2.NORM_L2, crossCheck=False)\n",
    "\n",
    "    # Step 4: Find the top two matches for each descriptor in img1\n",
    "    matches = bf.knnMatch(descriptors1, descriptors2, k=2)\n",
    "\n",
    "    # Step 5: Apply ratio test to keep only good matches\n",
    "    good_matches = []\n",
    "    for m, n in matches:\n",
    "        if m.distance < ratio_test * n.distance:\n",
    "            good_matches.append(m)\n",
    "\n",
    "    # Step 6: Extract matched keypoints positions\n",
    "    pts1 = np.float32([keypoints1[m.queryIdx].pt for m in good_matches])\n",
    "    pts2 = np.float32([keypoints2[m.trainIdx].pt for m in good_matches])\n",
    "\n",
    "    # Step 7: RANSAC to filter out outliers \n",
    "    best_H, inliers, outliers = ransac_outlier_rejection(pts1, pts2, ransac_thresh)\n",
    "    # Step 8: Plot inliers in blue and outliers in red\n",
    "    plot_inliers_outliers(img1, img2, pts1, pts2, inliers, outliers, output_name)\n",
    "\n",
    "    H_inliner, inlier_pts1, inlier_pts2= compute_homography_from_inliers(pts1, pts2, inliers)\n",
    "\n",
    "    # H_refined = refine_homography(H_inliner, inlier_pts1, inlier_pts2)\n",
    "    \n",
    "    # Extra credit\n",
    "    initial_error = compute_average_error(H_inliner, inlier_pts1, inlier_pts2)\n",
    "    H_refined=refine_homography_lm(H_inliner, inlier_pts1, inlier_pts2, max_iters=100, lambda_init=1e-3, tol=1e-6)\n",
    "    refined_error = compute_average_error(H_refined, inlier_pts1, inlier_pts2)\n",
    "    # Improvement percentage\n",
    "    improvement = 100 * (initial_error - refined_error) / initial_error\n",
    "    print(f\"Improvement after LM refinement: {improvement:.2f}%\")\n",
    "\n",
    "    return H_refined\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def warp_image(img, H, output_shape):\n",
    "    \"\"\"\n",
    "    Warp the input image 'img' using the homography 'H' into the 'output_shape' frame.\n",
    "    Apply scaling and interpolation.\n",
    "    \"\"\"\n",
    "    warped_img = cv2.warpPerspective(img, H, output_shape, flags=cv2.INTER_LINEAR)\n",
    "    return warped_img\n",
    "\n",
    "def compute_output_size_and_offset(images, homographies):\n",
    "    \"\"\"\n",
    "    Compute the size of the output panorama and the necessary translation to ensure all images fit.\n",
    "    images: List of input images\n",
    "    homographies: List of homographies relative to the reference frame\n",
    "    \"\"\"\n",
    "    # Initialize variables to keep track of the overall bounding box\n",
    "    min_x, min_y = 0, 0\n",
    "    max_x, max_y = images[0].shape[1], images[0].shape[0]\n",
    "\n",
    "    # Transform the corners of each image and track the bounding box\n",
    "    for i, H in enumerate(homographies):\n",
    "        h, w = images[i].shape[:2]\n",
    "        corners = np.array([[0, 0], [w, 0], [w, h], [0, h]], dtype=np.float32)\n",
    "        projected_corners = cv2.perspectiveTransform(corners.reshape(-1, 1, 2), H).reshape(-1, 2)\n",
    "\n",
    "        # Update bounding box limits\n",
    "        min_x = min(min_x, np.min(projected_corners[:, 0]))\n",
    "        min_y = min(min_y, np.min(projected_corners[:, 1]))\n",
    "        max_x = max(max_x, np.max(projected_corners[:, 0]))\n",
    "        max_y = max(max_y, np.max(projected_corners[:, 1]))\n",
    "\n",
    "    # Compute the overall output size\n",
    "    output_shape = (int(np.ceil(max_x - min_x)), int(np.ceil(max_y - min_y)))\n",
    "\n",
    "    # Compute the translation homography to shift the mosaic to positive coordinates\n",
    "    offset_x = -min_x if min_x < 0 else 0\n",
    "    offset_y = -min_y if min_y < 0 else 0\n",
    "    translation_H = np.array([[1, 0, offset_x], [0, 1, offset_y], [0, 0, 1]])\n",
    "\n",
    "    return output_shape, translation_H\n",
    "\n",
    "def create_mosaic(images, pairwise_homographies):\n",
    "    \"\"\"\n",
    "    Create a mosaic by projecting all images onto a fixed common frame using pairwise homographies.\n",
    "    pairwise_homographies: Homographies between consecutive images.\n",
    "    \"\"\"\n",
    "    # Assume the middle image is the reference frame\n",
    "    mid_idx = len(images) // 2\n",
    "    H_to_ref_frame = [np.eye(3) for _ in range(len(images))]  # Homography to the reference frame\n",
    "\n",
    "    # Compute the homographies relative to the middle (reference) image\n",
    "    for i in range(mid_idx - 1, -1, -1):  # Left of the middle image\n",
    "        H_to_ref_frame[i] = np.dot(H_to_ref_frame[i + 1], pairwise_homographies[i])\n",
    "\n",
    "    for i in range(mid_idx + 1, len(images)):  # Right of the middle image\n",
    "        H_to_ref_frame[i] = np.dot(H_to_ref_frame[i - 1], np.linalg.inv(pairwise_homographies[i - 1]))\n",
    "\n",
    "    # Compute the output size and translation to fit all images\n",
    "    output_shape, translation_H = compute_output_size_and_offset(images, H_to_ref_frame)\n",
    "\n",
    "    # Initialize the mosaic\n",
    "    mosaic = np.zeros((output_shape[1], output_shape[0], 3), dtype=np.uint8)\n",
    "\n",
    "    # Warp each image to the mosaic frame\n",
    "    for i, img in enumerate(images):\n",
    "        # Combine homographies to map to the mosaic frame\n",
    "        H_to_mosaic = np.dot(translation_H, H_to_ref_frame[i])\n",
    "\n",
    "        # Warp the current image\n",
    "        warped_img = warp_image(img, H_to_mosaic, output_shape)\n",
    "\n",
    "        # Blend the warped image into the mosaic\n",
    "        mosaic = np.where(warped_img > 0, warped_img, mosaic)  # Simple blending by overwriting empty pixels\n",
    "\n",
    "    return mosaic\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_1 = cv2.imread('pics/1.jpg')\n",
    "img_2 = cv2.imread('pics/2.jpg')\n",
    "img_3 = cv2.imread('pics/3.jpg')\n",
    "img_4 = cv2.imread('pics/4.jpg')\n",
    "img_5 = cv2.imread('pics/5.jpg')\n",
    "\n",
    "H_refined_1 = sift_feature_matching_ransac(img_1, img_2, output_name='pair1_2.jpg')\n",
    "H_refined_2 = sift_feature_matching_ransac(img_2, img_3, output_name='pair2_3.jpg')\n",
    "H_refined_3 = sift_feature_matching_ransac(img_3, img_4, output_name='pair3_4.jpg')\n",
    "H_refined_4 = sift_feature_matching_ransac(img_4, img_5, output_name='pair4_5.jpg')\n",
    "\n",
    "# List of 5 images\n",
    "images = [img_1, img_2, img_3, img_4, img_5]\n",
    "\n",
    "# List of 4 pairwise homographies between consecutive images\n",
    "homographies = [H_refined_1, H_refined_2, H_refined_3, H_refined_4]\n",
    "\n",
    "# Create the mosaic\n",
    "mosaic = create_mosaic(images, homographies)\n",
    "\n",
    "# Save the mosaic image\n",
    "cv2.imwrite('mosaic_output.png', mosaic)\n",
    "\n",
    "\n",
    "# img_6 = cv2.imread('IMG_9722.jpg')\n",
    "# img_7 = cv2.imread('IMG_9723.jpg')\n",
    "# img_8 = cv2.imread('IMG_9724.jpg')\n",
    "# img_9 = cv2.imread('IMG_9725.jpg')\n",
    "# img_10 = cv2.imread('IMG_9726.jpg')\n",
    "\n",
    "# H_refined_5 = sift_feature_matching_ransac(img_6, img_7, output_name='pair6_7.jpg')\n",
    "# H_refined_6 = sift_feature_matching_ransac(img_7, img_8, output_name='pair7_8.jpg')\n",
    "# H_refined_7 = sift_feature_matching_ransac(img_8, img_9, output_name='pair8_9.jpg')\n",
    "# H_refined_8 = sift_feature_matching_ransac(img_9, img_10, output_name='pair9_10.jpg')\n",
    "\n",
    "\n",
    "# # List of 5 images\n",
    "# images = [img_6, img_7, img_8, img_9, img_10]\n",
    "\n",
    "# # List of 4 pairwise homographies between consecutive images\n",
    "# homographies = [H_refined_5, H_refined_6, H_refined_7, H_refined_8]\n",
    "\n",
    "# # Create the mosaic\n",
    "# mosaic = create_mosaic(images, homographies)\n",
    "\n",
    "# # Save the mosaic image\n",
    "# cv2.imwrite('mosaic_output_custom.png', mosaic)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
