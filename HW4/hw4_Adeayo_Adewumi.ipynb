{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.ndimage import gaussian_filter\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import io, color\n",
    "import cv2\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def harris_corner_detection(img, sigma, img_pair_id, k=0.05, threshold_factor=1):\n",
    "    \"\"\"\n",
    "    Perform Harris Corner Detection on an image.\n",
    "    \n",
    "    Parameters:\n",
    "    img: np.array\n",
    "        Input image.\n",
    "    sigma: float\n",
    "        Standard deviation for Gaussian window.\n",
    "    img_pair_id: str\n",
    "        ID for image pair, used in file output naming.\n",
    "    k: float, optional\n",
    "        Harris detector free parameter (default is 0.05).\n",
    "    threshold_factor: float, optional\n",
    "        Factor to adjust corner detection threshold (default is 1).\n",
    "    \n",
    "    Returns:\n",
    "    corners_top: np.array\n",
    "        Array of top corners detected.\n",
    "    img_output: np.array\n",
    "        Output image with corners drawn.\n",
    "    \"\"\"\n",
    "    # Convert the image to grayscale and normalize\n",
    "    img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY).astype(np.float32) / 255\n",
    "\n",
    "    # Haar-like filter for x and y derivatives\n",
    "    haar_x = np.array([[1, 0, -1], [1, 0, -1], [1, 0, -1]])\n",
    "    haar_y = np.array([[1, 1, 1], [0, 0, 0], [-1, -1, -1]])\n",
    "\n",
    "    # Apply convolution to get derivatives\n",
    "    dx = cv2.filter2D(img_gray, -1, haar_x)\n",
    "    dy = cv2.filter2D(img_gray, -1, haar_y)\n",
    "    \n",
    "    # Calculate products of derivatives\n",
    "    dx2 = dx * dx\n",
    "    dy2 = dy * dy\n",
    "    dxy = dx * dy\n",
    "\n",
    "    # Gaussian filter to smooth derivative products\n",
    "    gauss_kernel_size = (int(4 * sigma + 1), int(4 * sigma + 1))\n",
    "    dx2_sum = cv2.GaussianBlur(dx2, gauss_kernel_size, sigma)\n",
    "    dy2_sum = cv2.GaussianBlur(dy2, gauss_kernel_size, sigma)\n",
    "    dxy_sum = cv2.GaussianBlur(dxy, gauss_kernel_size, sigma)\n",
    "\n",
    "    # Compute Harris corner response\n",
    "    trace = dx2_sum + dy2_sum\n",
    "    det = dx2_sum * dy2_sum - dxy_sum**2\n",
    "    R = det - k * (trace**2)\n",
    "\n",
    "    # Determine threshold for corner detection\n",
    "    R_thresh = threshold_factor * np.mean(np.abs(R))\n",
    "\n",
    "    # Non-maximum suppression for corner points\n",
    "    corners = np.zeros_like(R)\n",
    "    N = int(5 * sigma)  # Window size is proportional to sigma\n",
    "\n",
    "    for y in range(N, img_gray.shape[0] - N):\n",
    "        for x in range(N, img_gray.shape[1] - N):\n",
    "            window = R[y - N:y + N + 1, x - N:x + N + 1]\n",
    "            R_max = np.max(window)\n",
    "            if R[y, x] == R_max and R_max > R_thresh:\n",
    "                corners[y, x] = R_max\n",
    "\n",
    "    # Get the top 100 corner points\n",
    "    corners_top = np.argpartition(corners.flatten(), -100)[-100:]\n",
    "    corners_top = np.vstack(np.unravel_index(corners_top, corners.shape)).T\n",
    "\n",
    "    # Output image with corners highlighted\n",
    "    img_output = img.copy()\n",
    "    for point in corners_top:\n",
    "        cv2.circle(img_output, tuple(point[::-1]), radius=4, color=(0, 0, 255), thickness=2)\n",
    "\n",
    "    # Save the output image (flexible path for portability)\n",
    "    output_filename = f'Harris_scale_{sigma}_{img_pair_id}.jpg'\n",
    "    cv2.imwrite(output_filename, img_output)\n",
    "\n",
    "    return corners_top, img_output\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ncc_metric(img1, img2, img1_corners, img2_corners, sigma, B, img_pair_id):\n",
    "    \"\"\"\n",
    "    Calculate the Normalized Cross-Correlation (NCC) metric between two images.\n",
    "    \n",
    "    Parameters:\n",
    "    img1: np.array\n",
    "        First input image.\n",
    "    img2: np.array\n",
    "        Second input image.\n",
    "    img1_corners: np.array\n",
    "        Corner points from image 1.\n",
    "    img2_corners: np.array\n",
    "        Corner points from image 2.\n",
    "    sigma: float\n",
    "        Standard deviation for Gaussian window.\n",
    "    B: int\n",
    "        Border size for padding.\n",
    "    img_pair_id: str\n",
    "        Image pair ID for saving the output image.\n",
    "    \n",
    "    Returns:\n",
    "    img12: np.array\n",
    "        Output image with corners and NCC results drawn.\n",
    "    \"\"\"\n",
    "    # Convert the images to grayscale and normalize\n",
    "    img1_gray = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY).astype(np.float32) / 255\n",
    "    img2_gray = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY).astype(np.float32) / 255\n",
    "\n",
    "    # Apply border padding to both images\n",
    "    img1_border = cv2.copyMakeBorder(img1_gray, B, B, B, B, cv2.BORDER_CONSTANT, value=0)\n",
    "    img2_border = cv2.copyMakeBorder(img2_gray, B, B, B, B, cv2.BORDER_CONSTANT, value=0)\n",
    "    # Prepare RGB versions of the bordered images for visualization\n",
    "    img1_RGB_border = cv2.copyMakeBorder(img1, B, B, B, B, cv2.BORDER_CONSTANT, value=0)\n",
    "    img2_RGB_border = cv2.copyMakeBorder(img2, B, B, B, B, cv2.BORDER_CONSTANT, value=0)\n",
    "\n",
    "    # Concatenate the images horizontally for display\n",
    "    img12 = np.concatenate((img1_RGB_border, img2_RGB_border), axis=1)\n",
    "\n",
    "    # Initialize NCC value array\n",
    "    ncc_values = np.zeros((len(img1_corners), 2))\n",
    "\n",
    "# Calculate NCC for each corner in img1 with each corner in img2\n",
    "    for i, coord1 in enumerate(img1_corners):\n",
    "        ncc = np.zeros((len(img2_corners), 2))\n",
    "        \n",
    "        for j, coord2 in enumerate(img2_corners):\n",
    "            # Check if window stays within bounds for img1\n",
    "            if coord1[1] + B > img1_border.shape[0] or coord1[0] + B > img1_border.shape[1]:\n",
    "                continue\n",
    "            \n",
    "            # Check if window stays within bounds for img2\n",
    "            if coord2[1] + B > img2_border.shape[0] or coord2[0] + B > img2_border.shape[1]:\n",
    "                continue\n",
    "\n",
    "            # Define the window region for both images\n",
    "            img1_window = img1_border[coord1[1]:coord1[1] + B, coord1[0]:coord1[0] + B]\n",
    "            img2_window = img2_border[coord2[1]:coord2[1] + B, coord2[0]:coord2[0] + B]\n",
    "\n",
    "            # Compute the means of the windows\n",
    "            m1, m2 = np.mean(img1_window), np.mean(img2_window)\n",
    "\n",
    "            # Calculate numerator and denominator of NCC\n",
    "            numer = np.sum((img1_window - m1) * (img2_window - m2))\n",
    "            denom = np.sqrt(np.sum((img1_window - m1) ** 2) * np.sum((img2_window - m2) ** 2))\n",
    "            \n",
    "            # Store NCC value if denominator is not zero\n",
    "            if denom != 0:\n",
    "                ncc[j] = numer / denom\n",
    "\n",
    "\n",
    "        # Find the maximum NCC value and the corresponding corner in img2\n",
    "        if np.max(ncc[:, 0]) > 0.3:\n",
    "            ncc_largest_idx = np.argmax(ncc[:, 0], axis=0)\n",
    "            coord2_largest = img2_corners[ncc_largest_idx]\n",
    "            \n",
    "            # Visualize the corresponding points\n",
    "            coord1_plot = coord1 + B  # Adjust for the border size\n",
    "            # coord2_plot = coord2_largest + np.array([B + width, B])  # Adjust for concatenated image\n",
    "            coord2_plot = coord2_largest + np.array([B*3 + img1_RGB_border.shape[1], B])\n",
    "            random_color = (random.randint(0, 255), random.randint(0, 255), random.randint(0, 255))\n",
    "            cv2.circle(img12, tuple(coord1_plot), radius=4, color=(0, 0, 255), thickness=2)\n",
    "            cv2.circle(img12, tuple(coord2_plot), radius=4, color=(255, 0, 0), thickness=2)\n",
    "            cv2.line(img12, tuple(coord1_plot), tuple(coord2_plot), color=random_color, thickness=1)\n",
    "    \n",
    "    # Save the output image\n",
    "    output_filename = f'NCC_{img_pair_id}_scale_{sigma}.jpg'\n",
    "    cv2.imwrite(output_filename, img12)\n",
    "    print(f\"Saved image as {output_filename}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def SSD_metric(img1, img2, img1_corners, img2_corners, sigma, B, img_pair_id):\n",
    "    # Convert images to grayscale and normalize\n",
    "    img1_gray = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY).astype(np.float32) / 255\n",
    "    img2_gray = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY).astype(np.float32) / 255\n",
    "\n",
    "    # Apply border padding to both images to handle boundary conditions\n",
    "    img1_border = cv2.copyMakeBorder(img1_gray, B, B, B, B, cv2.BORDER_CONSTANT, value=0)\n",
    "    img2_border = cv2.copyMakeBorder(img2_gray, B, B, B, B, cv2.BORDER_CONSTANT, value=0)\n",
    "\n",
    "    # Prepare RGB versions of the bordered images for visualization\n",
    "    img1_RGB_border = cv2.copyMakeBorder(img1, B, B, B, B, cv2.BORDER_CONSTANT, value=0)\n",
    "    img2_RGB_border = cv2.copyMakeBorder(img2, B, B, B, B, cv2.BORDER_CONSTANT, value=0)\n",
    "\n",
    "    # Concatenate the two images horizontally for easier visualization\n",
    "    img12 = np.concatenate((img1_RGB_border, img2_RGB_border), axis=1)\n",
    "\n",
    "    # Initialize SSD values for storing results\n",
    "    SSD_shortest = np.zeros((len(img1_corners)))\n",
    "    \n",
    "    # Get the width of the first image (before concatenation)\n",
    "    width = img1.shape[1]\n",
    "\n",
    "    # Calculate SSD for each corner in img1 compared to all corners in img2\n",
    "    for i, coord1 in enumerate(img1_corners):\n",
    "        SSD = np.zeros((len(img2_corners)))\n",
    "\n",
    "        for j, coord2 in enumerate(img2_corners):\n",
    "            # Define the windows (patches) in both images based on the corners\n",
    "            img1_window = img1_border[coord1[1]:coord1[1] + B, coord1[0]:coord1[0] + B]\n",
    "            img2_window = img2_border[coord2[1]:coord2[1] + B, coord2[0]:coord2[0] + B]\n",
    "\n",
    "            # Ensure both windows have the correct size before comparing\n",
    "            if img1_window.shape == img2_window.shape and img1_window.size == B * B:\n",
    "                # Compute the SSD metric between the windows\n",
    "                SSD[j] = np.sum((img1_window - img2_window) ** 2)\n",
    "\n",
    "        # Store the index of the best match in img2 based on the smallest SSD\n",
    "        SSD_shortest[i] = np.argmin(SSD)\n",
    "\n",
    "    # Visualize the SSD correspondence result\n",
    "    for i, coord1 in enumerate(img1_corners):\n",
    "        # Get the corresponding point in img2 with the minimum SSD\n",
    "        coord2 = img2_corners[int(SSD_shortest[i])]\n",
    "\n",
    "        # Adjust for borders and concatenation\n",
    "        coord1_plot = coord1 + B  # Adjust for the border\n",
    "        coord2_plot = coord2 + np.array([B + width, B])  # Adjust for the border and concatenation\n",
    "        random_color = (random.randint(0, 255), random.randint(0, 255), random.randint(0, 255))\n",
    "\n",
    "        # Draw circles at the corresponding points\n",
    "        cv2.circle(img12, tuple(coord1_plot), radius=4, color=(0, 0, 255), thickness=2)  # Red circle for img1\n",
    "        cv2.circle(img12, tuple(coord2_plot), radius=4, color=(255, 0, 0), thickness=2)  # Blue circle for img2\n",
    "        cv2.line(img12, tuple(coord1_plot), tuple(coord2_plot), color=random_color, thickness=1)  # Green line\n",
    "\n",
    "    # Save the output image showing the SSD correspondences\n",
    "    output_filename = f'SSD_{img_pair_id}_scale_{sigma}.jpg'\n",
    "    cv2.imwrite(output_filename, img12)\n",
    "    print(f\"Saved image as {output_filename}\")\n",
    "\n",
    "    # return img12\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sift_feature_matching(img1, img2, ratio_test=0.75):\n",
    "    # Step 1: Initialize the SIFT detector\n",
    "    sift = cv2.SIFT_create()\n",
    "\n",
    "    # Step 2: Detect keypoints and compute descriptors for both images\n",
    "    keypoints1, descriptors1 = sift.detectAndCompute(img1, None)\n",
    "    keypoints2, descriptors2 = sift.detectAndCompute(img2, None)\n",
    "\n",
    "    # Step 3: Use BFMatcher to match descriptors\n",
    "    bf = cv2.BFMatcher(cv2.NORM_L2, crossCheck=False)\n",
    "\n",
    "    # Step 4: Find the top two matches for each descriptor in img1\n",
    "    matches = bf.knnMatch(descriptors1, descriptors2, k=2)\n",
    "\n",
    "    # Step 5: Apply ratio test to keep only good matches\n",
    "    good_matches = []\n",
    "    for m, n in matches:\n",
    "        if m.distance < ratio_test * n.distance:\n",
    "            good_matches.append(m)\n",
    "\n",
    "    # Step 6: Draw matches\n",
    "    match_img = cv2.drawMatches(\n",
    "        img1, keypoints1, img2, keypoints2, good_matches, None,\n",
    "        flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS\n",
    "    )\n",
    "\n",
    "    # Step 7: Return the image with matches\n",
    "    return match_img, keypoints1, keypoints2, good_matches\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved image as NCC_pair1_scale_1.2.jpg\n",
      "Saved image as SSD_pair1_scale_1.2.jpg\n",
      "Saved image as NCC_pair2_scale_1.2.jpg\n",
      "Saved image as SSD_pair2_scale_1.2.jpg\n",
      "Saved image as NCC_pair1_scale_1.6.jpg\n",
      "Saved image as SSD_pair1_scale_1.6.jpg\n",
      "Saved image as NCC_pair2_scale_1.6.jpg\n",
      "Saved image as SSD_pair2_scale_1.6.jpg\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.10.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\smooth.dispatch.cpp:294: error: (-215:Assertion failed) ksize.width > 0 && ksize.width % 2 == 1 && ksize.height > 0 && ksize.height % 2 == 1 in function 'cv::createGaussianKernels'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m sigmas\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m1.2\u001b[39m, \u001b[38;5;241m1.6\u001b[39m, \u001b[38;5;241m1.8\u001b[39m, \u001b[38;5;241m2.0\u001b[39m]\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sigma \u001b[38;5;129;01min\u001b[39;00m sigmas:\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;66;03m# Hovde\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m     corners_hv_2, hovde_img_2_harr \u001b[38;5;241m=\u001b[39m \u001b[43mharris_corner_detection\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhovde_img_2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msigma\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msigma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg_pair_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhovde_2\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m     corners_hv_3, hovde_img_3_harr \u001b[38;5;241m=\u001b[39m harris_corner_detection(hovde_img_3, sigma\u001b[38;5;241m=\u001b[39msigma, img_pair_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhovde_3\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;66;03m#  Temple\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[27], line 41\u001b[0m, in \u001b[0;36mharris_corner_detection\u001b[1;34m(img, sigma, img_pair_id, k, threshold_factor)\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# Gaussian filter to smooth derivative products\u001b[39;00m\n\u001b[0;32m     40\u001b[0m gauss_kernel_size \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mint\u001b[39m(\u001b[38;5;241m4\u001b[39m \u001b[38;5;241m*\u001b[39m sigma \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m), \u001b[38;5;28mint\u001b[39m(\u001b[38;5;241m4\u001b[39m \u001b[38;5;241m*\u001b[39m sigma \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m---> 41\u001b[0m dx2_sum \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mGaussianBlur\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdx2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgauss_kernel_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msigma\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     42\u001b[0m dy2_sum \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mGaussianBlur(dy2, gauss_kernel_size, sigma)\n\u001b[0;32m     43\u001b[0m dxy_sum \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mGaussianBlur(dxy, gauss_kernel_size, sigma)\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.10.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\smooth.dispatch.cpp:294: error: (-215:Assertion failed) ksize.width > 0 && ksize.width % 2 == 1 && ksize.height > 0 && ksize.height % 2 == 1 in function 'cv::createGaussianKernels'\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "hovde_img_2 = cv2.imread('hovde_2.jpg')\n",
    "hovde_img_3 = cv2.imread('hovde_3.jpg')\n",
    "temple_img_1 = cv2.imread('temple_1.jpg')\n",
    "temple_img_2 = cv2.imread('temple_2.jpg')\n",
    "\n",
    "sigmas=[1.2, 1.6, 2.0]\n",
    "for sigma in sigmas:\n",
    "    # Hovde\n",
    "    corners_hv_2, hovde_img_2_harr = harris_corner_detection(hovde_img_2, sigma=sigma, img_pair_id='hovde_2')\n",
    "    corners_hv_3, hovde_img_3_harr = harris_corner_detection(hovde_img_3, sigma=sigma, img_pair_id='hovde_3')\n",
    "    #  Temple\n",
    "    corners_hv_4, temple_img_1_harr = harris_corner_detection(temple_img_1, sigma=sigma, img_pair_id='temple_1')\n",
    "    corners_hv_5, temple_img_2_harr = harris_corner_detection(temple_img_2, sigma=sigma, img_pair_id='temple_2')\n",
    "\n",
    "    # Evaluation\n",
    "    # Temple\n",
    "    ncc_metric(hovde_img_2, hovde_img_3, corners_hv_2, corners_hv_3, sigma=sigma, B=10, img_pair_id='pair1')\n",
    "    SSD_metric(hovde_img_2, hovde_img_3, corners_hv_2, corners_hv_3, sigma=sigma, B=10, img_pair_id='pair1')\n",
    "    # Hovde\n",
    "    ncc_metric(temple_img_1, temple_img_2, corners_hv_4, corners_hv_5, sigma=sigma, B=10, img_pair_id='pair2')\n",
    "    SSD_metric(temple_img_1, temple_img_2, corners_hv_4, corners_hv_5, sigma=sigma, B=10, img_pair_id='pair2')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SIFT \n",
    "match_img, kp1, kp2, matches = sift_feature_matching(hovde_img_2, hovde_img_3)\n",
    "# Save and show the result\n",
    "cv2.imwrite('sift_matches.jpg', match_img)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envhw",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
